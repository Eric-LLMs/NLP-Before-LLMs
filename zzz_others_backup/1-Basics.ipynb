{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://discuss.pytorch.org/uploads/default/original/2X/3/35226d9fbc661ced1c5d17e374638389178c3176.png\" width=\"400\" style=\"margin: 50px auto; display: block; position: relative; left: -30px;\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "# | Basics | [Autograd >](2-Autograd.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basics\n",
    "\n",
    "In this first notebook, we will introduce Tensors, which are the base element in PyTorch.  \n",
    "We will see different ways to create Tensors and check their properties. Then, we will briefly go through all the different kind of operations they support, such as mathematical operations, indexing, reshaping, expansion, masking, type conversion, etc.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "#### 1. [Introduction](#Introduction)  \n",
    "#### 2. [Tensor Creation](#Tensor-Creation)\n",
    "#### 3. [Tensor Properties](#Tensor-Properties)  \n",
    "#### 4. [Tensor Operations](#Tensor-Operations)  \n",
    "#### 5. [Tensor Conversions](#Tensor-Conversions)  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is PyTorch ?\n",
    "Python-based scientific computing library, similar to NumPy.  \n",
    "Differentiates from NumPy in 3 main aspects:\n",
    "- It allows to use the power of **GPU** computing\n",
    "- It comes with an **automatic differentiation** module\n",
    "- It is a fully-fledged **deep learning research platform**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T21:02:14.019025300Z",
     "start_time": "2024-11-07T21:02:13.979817100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T10:58:09.263213100Z",
     "start_time": "2024-11-07T10:58:06.489230500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T10:58:10.681339200Z",
     "start_time": "2024-11-07T10:58:10.646843500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a tensor?\n",
    "\n",
    "A **matrix** is a grid of numbers, let's say (3x5).  \n",
    "In simple terms, a **tensor** can be seen as a generalization of a matrix to higher dimension.  \n",
    "It can be of arbitrary shape, e.g. (3 x 6 x 2 x 10). \n",
    "\n",
    "You can think of tensors as multidimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:59:37.494072800Z",
     "start_time": "2024-11-07T16:59:37.435187900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4, 5])\n",
    "X\n",
    "# X.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:43:20.680503900Z",
     "start_time": "2024-11-07T16:43:20.638364700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:43:38.151729Z",
     "start_time": "2024-11-07T16:43:38.112279800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:43:48.495880300Z",
     "start_time": "2024-11-07T16:43:48.460488800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch vs NumPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` behaves like `numpy.array` under mathematical operations.  \n",
    "The syntax is very similar between the two libraries.  \n",
    "If you are familiar with NumPy, you can [browse here](https://github.com/wkentaro/pytorch-for-numpy-users#types) to check what are NumPy functions equivalent in PyTorch.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:44:12.631119100Z",
     "start_time": "2024-11-07T16:44:12.551408700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0.],\n       [0., 1.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:44:15.503995700Z",
     "start_time": "2024-11-07T16:44:15.362229600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0.],\n        [0., 1.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:44:28.146221200Z",
     "start_time": "2024-11-07T16:44:28.100149700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3, 4])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:44:49.387003Z",
     "start_time": "2024-11-07T16:44:49.279034800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said, `torch.tensor` additionally keeps track of the computation graphs (see next notebook) and provides GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:45:16.550858100Z",
     "start_time": "2024-11-07T16:45:16.435504600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0.])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:45:16.592439800Z",
     "start_time": "2024-11-07T16:45:16.497759700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1., 1., 1.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:46:40.213035300Z",
     "start_time": "2024-11-07T16:46:40.179154700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:46:41.501837400Z",
     "start_time": "2024-11-07T16:46:41.456633100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[9.2755e-39, 1.0561e-38, 9.2755e-39, 9.5510e-39, 9.6429e-39],\n        [4.2246e-39, 1.0286e-38, 1.0653e-38, 1.0194e-38, 8.4490e-39],\n        [1.0469e-38, 9.3674e-39, 9.9184e-39, 8.7245e-39, 9.2755e-39]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:46:42.859000900Z",
     "start_time": "2024-11-07T16:46:42.769344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7361, 0.7793, 0.2603],\n        [0.0933, 0.5223, 0.0893],\n        [0.3587, 0.3592, 0.2323],\n        [0.8325, 0.9118, 0.8488],\n        [0.5101, 0.7022, 0.6786]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:46:51.621121100Z",
     "start_time": "2024-11-07T16:46:51.551251800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3, 5, 7])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3, 9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:50:13.813338300Z",
     "start_time": "2024-11-07T16:50:13.759032900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n        0.9000, 1.0000])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:52:29.583337300Z",
     "start_time": "2024-11-07T16:52:29.545915300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.],\n        [0., 0., 0.]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones((2,3))\n",
    "torch.zeros_like(A)\n",
    "# torch.ones((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list is not exhaustive but gives you an idea of the diversity of way to create a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Create the tensor:_**\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "5 & 7 & 9 & 11 & 13 & 15 & 17 & 19\n",
    "\\end{bmatrix}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:01:11.233750200Z",
     "start_time": "2024-11-07T17:01:11.158426600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 5,  7,  9, 11, 13, 15, 17, 19])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "# torch.linspace(5,19,8)\n",
    "torch.arange(5,21,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.03rem 0.03rem 0.015rem 0.015rem;\">\n",
    "<h3 style=\"display: inline\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:01:25.137323Z",
     "start_time": "2024-11-07T17:01:25.059082700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: \n",
      "torch.Size([3, 3])\n",
      "\n",
      "x.size(): \n",
      "torch.Size([3, 3])\n",
      "\n",
      "x.size(0): \n",
      "3\n",
      "\n",
      "x.size(1): \n",
      "3\n",
      "\n",
      "x.dim(): \n",
      "2\n",
      "\n",
      "x.numel(): \n",
      "9\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[0,1,2], [3,4,5],[5,6,7]])\n",
    "\n",
    "print(\"x.shape: \\n%s\\n\" % (x.shape,))\n",
    "print(\"x.size(): \\n%s\\n\" % (x.size(),))\n",
    "print(\"x.size(0): \\n%s\\n\" % x.size(0))\n",
    "print(\"x.size(1): \\n%s\\n\" % x.size(1))\n",
    "print(\"x.dim(): \\n%s\\n\" % x.dim())\n",
    "print(\"x.numel(): \\n%s\\n\" % x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:01:26.261256400Z",
     "start_time": "2024-11-07T17:01:26.221606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.dtype: \n",
      "torch.float32\n",
      "\n",
      "x.device: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"x.dtype: \\n%s\\n\" % x.dtype)\n",
    "print(\"x.device: \\n%s\\n\" % x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nonzero` function returns indices of the non zero elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:06:32.903393200Z",
     "start_time": "2024-11-07T17:06:32.818458700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.nonzero(): \n",
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[0,1,2], [3,4,5]])\n",
    "\n",
    "print(\"x.nonzero(): \\n%s\\n\" % x.nonzero())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in NumPy, there are two ways to performs most operations in PyTorch:\n",
    " - using **`torch.op(tensor)`**\n",
    " - using **`tensor.op()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:24:26.455979500Z",
     "start_time": "2024-11-07T17:24:26.358425800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8954, 0.0781],\n        [0.4101, 0.6062],\n        [0.3438, 0.3483]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:24:29.795254900Z",
     "start_time": "2024-11-07T17:24:29.755912500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.4484, 1.0813],\n        [1.5069, 1.8334],\n        [1.4103, 1.4167]])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:24:30.929268500Z",
     "start_time": "2024-11-07T17:24:30.848853100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.4484, 1.0813],\n        [1.5069, 1.8334],\n        [1.4103, 1.4167]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily chain operators :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:24:32.514023900Z",
     "start_time": "2024-11-07T17:24:32.477391600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2228)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sqrt().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.4714, 0.0977, 0.0027])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sqrt().std(dim=1) # 第2维度 按照行[0.8954, 0.0781],[0.4101, 0.6062], [0.3438, 0.3483] 来求"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T17:25:37.042398600Z",
     "start_time": "2024-11-07T17:25:37.006913800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T17:25:44.595905200Z",
     "start_time": "2024-11-07T17:25:44.515712900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.1643, 1.6104],\n        [1.2910, 1.2031],\n        [1.3350, 1.3318]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.exp() + 2).sqrt() - 2 * X.log().sigmoid()  # be creative :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many more functions are available: sin, cos, tanh, bmm, cumsum, dot, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the norms of the row-vectors in matrix **X** without using `torch.norm()`.\n",
    "\n",
    "Remember: $$||\\vec{v}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}$$\n",
    "\n",
    "Hint: `X**2` computes the element-wise square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows norms: tensor([0.6753, 1.5669])\n"
     ]
    }
   ],
   "source": [
    "# X = torch.arange(2,10,4)\n",
    "X = torch.randn(2,3)\n",
    "X_squared = X ** 2\n",
    "R_sums = X_squared.sum(dim=1)\n",
    "R_norms = R_sums.sqrt()\n",
    "print(\"Rows norms:\", R_norms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T18:35:25.940129700Z",
     "start_time": "2024-11-07T18:35:25.882721800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:41:34.772121300Z",
     "start_time": "2024-11-07T18:41:34.717511800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 2., 3.],\n        [0., 2., 2., 3.],\n        [0., 1., 3., 3.],\n        [0., 1., 2., 4.]])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.eye(4) + torch.arange(4).repeat(4, 1).float()\n",
    "X\n",
    "# YOUR TURN\n",
    "\n",
    "# SOLUTION: tensor([3.8730, 4.1231, 4.3589, 4.5826])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2., 3., 4.],\n        [0., 1., 2., 3., 4.],\n        [0., 1., 2., 3., 4.],\n        [0., 1., 2., 3., 4.]])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.arange(2,8,2)\n",
    "X = torch.arange(5).repeat(4,1).float()\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T18:41:20.599853300Z",
     "start_time": "2024-11-07T18:41:20.522127Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.03rem 0.03rem 0.015rem 0.015rem;\">\n",
    "<h3 style=\"display: inline\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:41:43.718297Z",
     "start_time": "2024-11-07T18:41:43.627554300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7626, 0.8068],\n        [0.9445, 0.9549],\n        [0.4307, 0.7938]])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:42:01.838626Z",
     "start_time": "2024-11-07T18:42:01.743737500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(4.6934)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:42:06.598908100Z",
     "start_time": "2024-11-07T18:42:06.559536200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9549)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:43:03.199794300Z",
     "start_time": "2024-11-07T18:43:03.159459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7626, 0.8068],\n        [0.9445, 0.9549],\n        [0.4307, 0.7938]])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:43:12.649780500Z",
     "start_time": "2024-11-07T18:43:12.604378300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(4.6934)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.norm(p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.1102, 1.3431, 0.9032])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.norm(p=2,dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T18:44:33.703742600Z",
     "start_time": "2024-11-07T18:44:33.659684500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $X_{i,j}$ , compute $Y$ such that $Y_j = \\log \\big[ \\sum_j \\exp (X_{i,j}) \\big]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:47:45.425623Z",
     "start_time": "2024-11-07T18:47:45.351015Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.eye(4) + torch.arange(4).repeat(4, 1).float()\n",
    "\n",
    "# YOUR TURN\n",
    "\n",
    "# SOLUTION: tensor([3.4938, 3.5797, 3.7817, 4.1852])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.03rem 0.03rem 0.015rem 0.015rem;\">\n",
    "<h3 style=\"display: inline\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:47:50.009445700Z",
     "start_time": "2024-11-07T18:47:49.952168300Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:49:29.963777100Z",
     "start_time": "2024-11-07T18:49:29.904888500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0673, 0.2288, 0.1703],\n        [0.2288, 0.2170, 0.1922],\n        [0.1703, 0.1922, 0.1714]])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "Y.t() @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:50:52.896753Z",
     "start_time": "2024-11-07T18:50:52.819774800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0673, 0.2288, 0.1703],\n        [0.2288, 0.2170, 0.1922],\n        [0.1703, 0.1922, 0.1714]])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.t().matmul(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:51:01.498299Z",
     "start_time": "2024-11-07T18:51:01.443164500Z"
    }
   },
   "outputs": [],
   "source": [
    "# CAUTION: Operator '*' does element-wise multiplication, just like in numpy!\n",
    "# Y.t() * Y  # error, dimensions do not match for element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:52:45.511195700Z",
     "start_time": "2024-11-07T18:52:45.440200500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   102723.8125,  -2433174.0000,   2625566.0000],\n        [ -2433174.2500,  57634168.0000, -62191344.0000],\n        [  2625566.0000, -62191344.0000,  67108864.0000]])"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(Y.t() @ Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:53:38.910012800Z",
     "start_time": "2024-11-07T18:53:38.862411700Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:53:39.765770100Z",
     "start_time": "2024-11-07T18:53:39.733536500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1418)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.det() # determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:00:05.245345800Z",
     "start_time": "2024-11-07T19:00:05.194418500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.linalg_eig(\neigenvalues=tensor([ 2.1355+0.j, -0.5016+0.j, -0.1324+0.j]),\neigenvectors=tensor([[-0.5050+0.j, -0.4711+0.j,  0.3953+0.j],\n        [-0.6758+0.j, -0.2644+0.j, -0.7125+0.j],\n        [-0.5369+0.j,  0.8415+0.j,  0.5797+0.j]]))"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y.eig()\n",
    "# Y.linalg.eig()\n",
    "torch.linalg.eig(Y) # eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place operators (mutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that mutate the object end with an underscore, e.g. *add_*, *div_*, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:00:08.839288900Z",
     "start_time": "2024-11-07T19:00:08.800394400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.eye(3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:00:10.678731600Z",
     "start_time": "2024-11-07T19:00:10.635080500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6., 5., 5.],\n        [5., 6., 5.],\n        [5., 5., 6.]])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.add(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:00:16.293324400Z",
     "start_time": "2024-11-07T19:00:16.198696800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:00:39.927571500Z",
     "start_time": "2024-11-07T19:00:39.828698300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6., 5., 5.],\n        [5., 6., 5.],\n        [5., 5., 6.]])"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.add_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:02:57.658561800Z",
     "start_time": "2024-11-07T19:02:57.568080300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.0000, 1.6667, 1.6667],\n        [1.6667, 2.0000, 1.6667],\n        [1.6667, 1.6667, 2.0000]])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.div_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:03:00.832986900Z",
     "start_time": "2024-11-07T19:03:00.786262600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.0000, 1.6667, 1.6667],\n        [1.6667, 2.0000, 1.6667],\n        [1.6667, 1.6667, 2.0000]])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:03:01.966231700Z",
     "start_time": "2024-11-07T19:03:01.928471600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3765, 0.9563, 0.5972],\n        [0.3140, 0.1772, 0.7899],\n        [0.8895, 0.1876, 0.0497]])"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.uniform_()  # fills the tensor with random uniform numbers in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:03:33.937443800Z",
     "start_time": "2024-11-07T19:03:33.891824600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3765, 0.9563, 0.5972],\n        [0.3140, 0.1772, 0.7899],\n        [0.8895, 0.1876, 0.0497]])"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.7457, -0.8798,  0.8985],\n        [ 0.4566, -1.5843, -2.1525]])"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.randn(2,3)\n",
    "B"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:08:06.657050600Z",
     "start_time": "2024-11-07T19:08:06.565778200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8985)"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:09:36.153759100Z",
     "start_time": "2024-11-07T19:09:36.115422900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enhui\\AppData\\Local\\Temp\\ipykernel_7708\\2311447644.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = torch.tensor(B)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-1.7457, -0.8798,  0.8985],\n        [ 0.4566, -1.5843, -2.1525]])"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.tensor(B)\n",
    "C"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:08:08.280409100Z",
     "start_time": "2024-11-07T19:08:08.190699500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([0.8985, 0.4566]),\nindices=tensor([2, 0]))"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_max = C.max(dim=1)\n",
    "row_max"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:11:27.020771900Z",
     "start_time": "2024-11-07T19:11:26.923270700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1.])"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(3)\n",
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:18:07.173635300Z",
     "start_time": "2024-11-07T19:18:07.135361900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also note the difference:\n",
    "```python\n",
    "A = A + 1  # After this operation, A is a new variable and memory has been copied\n",
    "A += 1     # After this operation, A stayed the same variable and memory has been changed in place\n",
    "```\n",
    "\n",
    "Compare the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:18:31.540903500Z",
     "start_time": "2024-11-07T19:18:31.484955300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2.]) tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(2)\n",
    "A_before = A\n",
    "A = A + 1\n",
    "\n",
    "print(A, A_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2., 2.])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:15:39.013676900Z",
     "start_time": "2024-11-07T19:15:38.971363500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:19:10.815195700Z",
     "start_time": "2024-11-07T19:19:10.744421300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2.]) tensor([2., 2.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(2)\n",
    "\n",
    "A_before = A\n",
    "A += 1\n",
    "\n",
    "print(A, A_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it works just like in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:03.484495800Z",
     "start_time": "2024-11-07T19:37:03.436344500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2077,  943, 1185],\n        [1150, 2190, 1672],\n        [1922,  164,  217]])"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randint(2200, (3, 3)) # 创建一个3x3的张量，元素是0到2199之间的随机整数\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:12.038062200Z",
     "start_time": "2024-11-07T19:37:11.952814900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2077)"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:13.873269400Z",
     "start_time": "2024-11-07T19:37:13.777983600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(164)"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:18.754992100Z",
     "start_time": "2024-11-07T19:37:18.709000200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1150, 2190, 1672])"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:21.368801600Z",
     "start_time": "2024-11-07T19:37:21.278017500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 943, 2190,  164])"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:37:56.154662300Z",
     "start_time": "2024-11-07T19:37:56.090310500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 943],\n         [2190],\n         [ 164]]),\n torch.Size([3, 1]))"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:, 1:2], A[:, 1:2].shape # [1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:39:33.247704800Z",
     "start_time": "2024-11-07T19:39:33.198464400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1150, 2190],\n        [1922,  164]])"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: You can use `...` to mark any number of dimension_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:41:03.884107900Z",
     "start_time": "2024-11-07T19:41:03.831332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n        [ 8,  9, 10, 11, 12, 13, 14, 15],\n        [16, 17, 18, 19, 20, 21, 22, 23],\n        [24, 25, 26, 27, 28, 29, 30, 31],\n        [32, 33, 34, 35, 36, 37, 38, 39]])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(40).view(5,8)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Extract this vector from the tensor X:_**\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "17 & 19 & 21 & 23 \\\\\n",
    "\\end{bmatrix}  $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:45:26.398329700Z",
     "start_time": "2024-11-07T19:45:26.348752900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([17, 19, 21, 23])"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN 1:8:2: This selects the elements from index 1 to index 7, with a step of 2, which corresponds to columns 1, 3, 5, and 7. The step of 2 ensures we skip every other column.\n",
    "X[2,1:8:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping & Expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`view`** is the equivalent of `reshape` in NumPy, but `view` does not allocate new memory: the output tensor shares the same data!\n",
    "\n",
    "The number of arguments of `view` will be the number of dimensions of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:46:28.500167300Z",
     "start_time": "2024-11-07T19:46:28.419536100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5, 6])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:46:34.584622600Z",
     "start_time": "2024-11-07T19:46:34.528676700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6]])"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = X.view(2, 3)  # view tensor X on 2 dimensions, with a size 2 on dimension 1 and a size 3 on dimension 2\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:47:31.878451500Z",
     "start_time": "2024-11-07T19:47:31.778260200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 2, 3, 4, 5, 6]), torch.Size([6]))"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = X.view(-1)  # -1 tells PyTorch to infer the number of elements along that dimension\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:57:15.633187Z",
     "start_time": "2024-11-07T19:57:15.591781800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1, 2],\n         [3, 4],\n         [5, 6]]),\n torch.Size([3, 2]))"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = X.view(-1, 2) # -1 自动计算行数大小， 2 设为2列\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`expand`** creates a new view of the tensor with dimensions of size 1 expanded to a larger size. This does not allocate new memory either !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:57:31.228884100Z",
     "start_time": "2024-11-07T19:57:31.177475300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1., 1., 1., 1., 1.]), torch.Size([5]))"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.ones(5)\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:57:40.922467800Z",
     "start_time": "2024-11-07T19:57:40.883768900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.]]),\n torch.Size([5, 1]))"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.view(-1, 1)\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:59:16.441635500Z",
     "start_time": "2024-11-07T19:59:16.397129200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.expand(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.6716,  0.9204, -1.5056],\n        [ 1.3430,  1.6325, -0.5413]])"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y= torch.randn(2,3)\n",
    "Y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T19:59:57.287284900Z",
     "start_time": "2024-11-07T19:59:57.245475500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.6716,  0.9204, -1.5056,  1.3430,  1.6325, -0.5413],\n        [ 0.6716,  0.9204, -1.5056,  1.3430,  1.6325, -0.5413],\n        [ 0.6716,  0.9204, -1.5056,  1.3430,  1.6325, -0.5413],\n        [ 0.6716,  0.9204, -1.5056,  1.3430,  1.6325, -0.5413]])"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.view(-1)\n",
    "Y.expand(4,6) # expand() 只能在维度大小为 1 或原始张量的某些维度可以广播的情况下使用。\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:03:28.888137500Z",
     "start_time": "2024-11-07T20:03:28.795814500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:03:41.983861400Z",
     "start_time": "2024-11-07T20:03:41.934597300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0., 0., 0., 1.]]), torch.Size([1, 4]))"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.eye(4)\n",
    "Y = X[3:, :]\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`squeeze` and `unsqueeze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:10:30.689417600Z",
     "start_time": "2024-11-07T20:10:30.619000700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0., 0., 0., 1.]), torch.Size([4]))"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.squeeze()  # removes all dimensions of size '1'\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:10:35.915458400Z",
     "start_time": "2024-11-07T20:10:35.874481900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.],\n         [0.],\n         [0.],\n         [1.]]),\n torch.Size([4, 1]))"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.unsqueeze(1)  # add a new dimension in position 1\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: There also exists `reshape` and `repeat` functions in PyTorch. They work similarly to `view` and `expand` but **do** copy memory_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Create the tensor:_**\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "7 & 5 & 5 & 5 & 5 \\\\\n",
    "5 & 7 & 5 & 5 & 5 \\\\\n",
    "5 & 5 & 7 & 5 & 5 \\\\\n",
    "5 & 5 & 5 & 7 & 5 \\\\\n",
    "5 & 5 & 5 & 5 & 7 \n",
    "\\end{bmatrix}  $\n",
    "\n",
    "Hint: You can use matrix sum and scalar multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:13:42.701854600Z",
     "start_time": "2024-11-07T20:13:42.666597600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[7., 5., 5., 5., 5.],\n        [5., 7., 5., 5., 5.],\n        [5., 5., 7., 5., 5.],\n        [5., 5., 5., 7., 5.],\n        [5., 5., 5., 5., 7.]])"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "X = torch.ones(5,5)*5 + torch.eye(5)*2\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[7, 5, 5, 5, 5],\n        [5, 7, 5, 5, 5],\n        [5, 5, 7, 5, 5],\n        [5, 5, 5, 7, 5],\n        [5, 5, 5, 5, 7]])"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个 5x5 的矩阵，初始值为 5\n",
    "matrix = torch.full((5, 5), 5)\n",
    "\n",
    "# 在对角线上填充 7\n",
    "matrix.fill_diagonal_(7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:14:20.037798100Z",
     "start_time": "2024-11-07T20:14:19.944879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Create the tensor:_**\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "4 & 6 & 8 & 10 & 12 \\\\\n",
    "14 & 16 & 18 & 20 & 22 \\\\\n",
    "24 & 26 & 28 & 30 & 32\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:15:31.459428500Z",
     "start_time": "2024-11-07T20:15:31.366809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 4,  6,  8, 10, 12],\n        [14, 16, 18, 20, 22],\n        [24, 26, 28, 30, 32]])"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "# 创建一个包含从 4 到 32 的数值，步长为 2 的 1D 张量\n",
    "tensor = torch.arange(4, 33, 2)\n",
    "\n",
    "# 将 1D 张量重塑为 3x5 的矩阵\n",
    "tensor = tensor.view(3, 5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Create the tensor:_**\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "2 & 2 & 2 & 2 & 2 \\\\\n",
    "4 & 4 & 4 & 4 & 4 \\\\\n",
    "6 & 6 & 6 & 6 & 6 \\\\\n",
    "8 & 8 & 8 & 8 & 8\n",
    "\\end{bmatrix}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:20:06.887463900Z",
     "start_time": "2024-11-07T20:20:06.827999800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 2, 2, 2, 2],\n        [4, 4, 4, 4, 4],\n        [6, 6, 6, 6, 6],\n        [8, 8, 8, 8, 8]])"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "# X = torch.arange(2,9,2).t()\n",
    "X = torch.arange(2,9,2).view(4,1)\n",
    "X.expand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 2, 2, 2, 2],\n        [4, 4, 4, 4, 4],\n        [6, 6, 6, 6, 6],\n        [8, 8, 8, 8, 8]])"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个 1D 张量，包含 [2, 4, 6, 8]\n",
    "tensor = torch.arange(2, 10, 2)\n",
    "\n",
    "# 重复每个元素 5 次，得到形状为 (4, 5) 的矩阵\n",
    "tensor = tensor.repeat(5, 1).t()\n",
    "tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:20:41.975057500Z",
     "start_time": "2024-11-07T20:20:41.929000700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:20:52.827141300Z",
     "start_time": "2024-11-07T20:20:52.769751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[83, 11, 98],\n        [46, 35, 29],\n        [58, 75, 49],\n        [30, 85,  4],\n        [64, 40, 66]])"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randint(100, (5, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:24:23.613504600Z",
     "start_time": "2024-11-07T20:24:23.576364300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[False, False, False],\n        [False, False, False],\n        [False, False, False],\n        [False, False, False],\n        [False, False, False]])"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X[mask] 是一个 索引操作，它返回的是符合条件的元素，而不是修改矩阵。如果你想修改矩阵中的元素，应该直接进行赋值操作，例如 X[mask] = new_value。\n",
    "mask = (X > 25) & (X < 75) \n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:24:30.235154300Z",
     "start_time": "2024-11-07T20:24:30.181833300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([], dtype=torch.int64)"
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[mask]  # returns all elements matching the criteria in a 1D-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:26:03.124650600Z",
     "start_time": "2024-11-07T20:26:03.052239100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0)"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask.sum() 计算的是 布尔掩码 (mask) 张量中 True 元素的数量。\n",
    "mask.sum()  # number of elements that fulfill the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:26:11.980805900Z",
     "start_time": "2024-11-07T20:26:11.922666800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ True, False,  True],\n        [False, False, False],\n        [False,  True, False],\n        [False,  True, False],\n        [False, False, False]])"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X == 25) | (X > 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:26:14.608218300Z",
     "start_time": "2024-11-07T20:26:14.484591200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[83, 11, 98],\n        [ 0,  0,  0],\n        [ 0, 75,  0],\n        [ 0, 85,  4],\n        [ 0,  0,  0]])"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[mask] = 0  # You can assign new values only to indices matching the condition:\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\">Your turn!</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:26:17.331474300Z",
     "start_time": "2024-11-07T20:26:17.274253100Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[1, 0, 2], [4, 6, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of non-zeros in **X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:26:59.241875300Z",
     "start_time": "2024-11-07T20:26:59.126851100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(4)"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "mask = X!=0\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sum of all entries in **X** that are larger than the mean of all values in **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:37:58.548708800Z",
     "start_time": "2024-11-07T20:37:58.455979700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1667)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(2)"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "print(X.float().mean())\n",
    "mask = X > X.float().mean()\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip _(limit)_ all values of **X** between 0 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 2],\n        [0, 0, 0]])"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN\n",
    "mask = (X <= 0) | (X >= 3)\n",
    "X[mask] = 0\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:45:46.620938300Z",
     "start_time": "2024-11-07T20:45:46.578535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:46:37.110173200Z",
     "start_time": "2024-11-07T20:46:37.063963500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 2],\n        [1, 1, 1]])"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 用于将张量的元素值限制在给定的范围内（即“裁剪”值）。它会将张量中所有小于指定最小值的元素设置为最小值，将所有大于指定最大值的元素设置为最大值，其他元素保持不变。\n",
    "X.clamp(1,3) # 会替换为最小值或最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue;padding:1rem;border-radius: 0.015rem 0.015rem 0.03rem 0.03rem;\">\n",
    "<h3 style=\"display: inline; font-weight:bold\"></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And many more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:46:43.733256500Z",
     "start_time": "2024-11-07T20:46:43.658918800Z"
    }
   },
   "outputs": [],
   "source": [
    "# press tab to autocomplete\n",
    "# x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tensor Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to cast a Tensor to a different type is to use the `Tensor.to(type)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:49:35.593473100Z",
     "start_time": "2024-11-07T20:49:35.534741800Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = 4 * torch.rand((2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:49:36.581285600Z",
     "start_time": "2024-11-07T20:49:36.493738700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.float32"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:49:37.374785200Z",
     "start_time": "2024-11-07T20:49:37.314168500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4409, 3.0586, 1.5166, 2.3223],\n        [3.9980, 3.8906, 0.7378, 0.3477]], dtype=torch.float16)"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:50:36.637449300Z",
     "start_time": "2024-11-07T20:50:36.578024900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 3, 2],\n        [1, 2, 2, 2]])"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:50:38.895354700Z",
     "start_time": "2024-11-07T20:50:38.847735900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ True, False,  True,  True],\n        [ True,  True,  True,  True]])"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y = torch.tensor([[1, 0, 3, 2], [1, 2, 2, 2]])\n",
    "\n",
    "Y.to(torch.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the automatic type promotion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:52:39.837326100Z",
     "start_time": "2024-11-07T20:52:39.744995500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.1000, 4.2000])"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会自动进行类型转换，使得不同类型的张量能够进行操作。自动类型提升（Type Promotion）具体来说：\n",
    "torch.LongTensor([1, 2]) + torch.FloatTensor([1.1, 2.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between PyTorch and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:52:53.604691200Z",
     "start_time": "2024-11-07T20:52:53.548565100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.20061144, 0.20142997, 0.50537475],\n       [0.61191462, 0.67426279, 0.2583529 ],\n       [0.20416085, 0.67493879, 0.89782829],\n       [0.274782  , 0.86010627, 0.96175885],\n       [0.51939046, 0.78995482, 0.22315873]])"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.random((5,3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:53:21.649747Z",
     "start_time": "2024-11-07T20:53:21.531892500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2006, 0.2014, 0.5054],\n        [0.6119, 0.6743, 0.2584],\n        [0.2042, 0.6749, 0.8978],\n        [0.2748, 0.8601, 0.9618],\n        [0.5194, 0.7900, 0.2232]], dtype=torch.float64)"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy ---> torch\n",
    "Y = torch.from_numpy(X)  # Y is actually a DoubleTensor (i.e. 64-bit representation)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:53:40.322962600Z",
     "start_time": "2024-11-07T20:53:40.281403500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4211, 0.6525, 0.5365, 0.0081],\n        [0.5373, 0.7564, 0.2275, 0.8730]])"
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand((2,4))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:53:42.570631500Z",
     "start_time": "2024-11-07T20:53:42.484391800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.4210863 , 0.65249944, 0.5365063 , 0.00805157],\n       [0.53734726, 0.7564038 , 0.22753996, 0.8730477 ]], dtype=float32)"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch ---> numpy\n",
    "X = Y.numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between GPU and CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you may want to check: \n",
    " - that cuda can actually be used : `torch.cuda.is_available()`\n",
    " - how many gpus are available : `torch.cuda.device_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:54:24.832467400Z",
     "start_time": "2024-11-07T20:54:24.739151400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:54:38.523238700Z",
     "start_time": "2024-11-07T20:54:38.430423400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:54:44.322564900Z",
     "start_time": "2024-11-07T20:54:44.266708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.device`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to easily move a tensor from a device to another is again by using the **`Tensor.to(...)`** function.  \n",
    "You need to pass as argument a **`torch.device`** object.\n",
    "\n",
    "A **`torch.device`** is an object representing the device on which a torch.tensor is or will be allocated.\n",
    "\n",
    "_Note : If you don't have Cuda on the machine, the following examples won't work_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:04.884653600Z",
     "start_time": "2024-11-07T20:55:04.724606800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[268], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(cpu)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m----> 6\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcuda_0\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda_0 = torch.device('cuda:0')\n",
    "\n",
    "x = x.to(cpu)\n",
    "print(x.device)\n",
    "x = x.to(cuda_0)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is flexible since you can check if cuda exists only once in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:11.928712900Z",
     "start_time": "2024-11-07T20:55:11.882871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = x.to(device)  # We don't need to worry anymore about whether cuda is available or not\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Tensor.cuda` and `Tensor.cpu`\n",
    "\n",
    "When you know in advance what device you want to move to, you can use the `Tensor.cuda()` and `Tensor.cpu()` functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:34.604423600Z",
     "start_time": "2024-11-07T20:55:34.503541300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:38.502619100Z",
     "start_time": "2024-11-07T20:55:38.417183100Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[271], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m      3\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x.cuda()\n",
    "print(x.device)\n",
    "x = x.cuda()\n",
    "print(x.device)\n",
    "x = x.cuda(1)\n",
    "print(x.device)\n",
    "x = x.cpu()\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:44.585420100Z",
     "start_time": "2024-11-07T20:55:44.471395300Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[272], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor([[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m], [\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m6\u001B[39m]])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# This will generate an error since you cannot do operation on tensor that are not on the same device\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m x \u001B[38;5;241m+\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "\n",
    "# This will generate an error since you cannot do operation on tensor that are not on the same device\n",
    "x + x.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write an if statement that moves x on gpu if cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:48.915557300Z",
     "start_time": "2024-11-07T20:55:48.790499900Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR TURN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kinds of if statements used to be all over the place in people's code.  \n",
    "Now, the more flexible `Tensor.to(...)` function is available and should be used preferably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much faster is GPU ?  See for yourself ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:55:57.623332700Z",
     "start_time": "2024-11-07T20:55:57.025502Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[274], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m A \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m1000\u001B[39m, \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m B \u001B[38;5;241m=\u001B[39m \u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m A\u001B[38;5;241m.\u001B[39msize()\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "A = torch.rand(100, 1000, 1000)\n",
    "B = A.cuda()\n",
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:00:10.769400Z",
     "start_time": "2024-11-07T20:59:43.894763900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28 s ± 169 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 3 torch.bmm(A, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:56:27.058410200Z",
     "start_time": "2024-11-07T20:56:26.631189400Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch1 must be a 3D tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[276], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m-n 30 torch.bmm(B, B)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2478\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2479\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2480\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2483\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2484\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1189\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1186\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1187\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1189\u001B[0m all_runs \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepeat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1190\u001B[0m best \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(all_runs) \u001B[38;5;241m/\u001B[39m number\n\u001B[0;32m   1191\u001B[0m worst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(all_runs) \u001B[38;5;241m/\u001B[39m number\n",
      "File \u001B[1;32mD:\\Anaconda3\\lib\\timeit.py:206\u001B[0m, in \u001B[0;36mTimer.repeat\u001B[1;34m(self, repeat, number)\u001B[0m\n\u001B[0;32m    204\u001B[0m r \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(repeat):\n\u001B[1;32m--> 206\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m     r\u001B[38;5;241m.\u001B[39mappend(t)\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[1;32mD:\\Anaconda3\\sk_env\\lib\\site-packages\\IPython\\core\\magics\\execution.py:173\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    171\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: batch1 must be a 3D tensor"
     ]
    }
   ],
   "source": [
    "%timeit -n 30 torch.bmm(B, B)\n",
    "\n",
    "# 解释：\n",
    "# %timeit：测量 torch.bmm(A, A) 代码的执行时间。\n",
    "# -n 3：指定 torch.bmm(A, A) 会执行 3 次，以便进行多次测量并计算平均时间和标准差。这里的 3 表示代码运行 3 次，timeit 会执行多次以便得出稳定的平均运行时间。\n",
    "# torch.bmm(A, A)：torch.bmm 是 批量矩阵乘法（batch matrix multiplication）的函数。它用于执行两个 3D 张量的批量矩阵乘法，假设 A 是一个 3D 张量，形状为 [batch_size, n, m]，则 torch.bmm(A, A) 会执行批量矩阵乘法，结果张量的形状为 [batch_size, n, n]。\n",
    "# 解释 torch.bmm：\n",
    "# torch.bmm(A, A) 的作用是对张量 A 中的每一对矩阵执行矩阵乘法。对于批量大小为 batch_size 的张量 A，torch.bmm(A, A) 将为每对矩阵执行乘法，生成批量矩阵乘法的结果。\n",
    "# \n",
    "# 假设：\n",
    "# \n",
    "# A 的形状是 [batch_size, n, m]，那么 torch.bmm(A, A) 将执行批量的矩阵乘法，产生一个形状为 [batch_size, n, n] 的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "# | Basics | [Autograd >](2-Autograd.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "sk_env",
   "language": "python",
   "display_name": "Python (sk_env)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
